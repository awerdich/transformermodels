{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd16dd6e-8a2b-42f7-a2bc-d7f187e4514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Package version: 0.0.post1.dev3+g8362a6c.d20240713\n",
      "PyTorch version: 2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from pprint import pprint\n",
    "import textwrap\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Hugging Face \n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import transformermodels as tm\n",
    "print(f'Package version: {tm.__version__}')\n",
    "print(f'PyTorch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d798d945-43c7-43e6-a843-fa99f19a2631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs found:  1\n",
      "Current device ID:     0\n",
      "GPU device name:       NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDNN version:         8902\n",
      "\n",
      "Device for model training/inference: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# GPU checks\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f'CUDA available: {is_cuda}')\n",
    "print(f'Number of GPUs found:  {torch.cuda.device_count()}')\n",
    "\n",
    "if is_cuda:\n",
    "    print(f'Current device ID:     {torch.cuda.current_device()}')\n",
    "    print(f'GPU device name:       {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDNN version:         {torch.backends.cudnn.version()}')\n",
    "    device_str = 'cuda:0'\n",
    "    torch.cuda.empty_cache() \n",
    "else:\n",
    "    device_str = 'cpu'\n",
    "device = torch.device(device_str)\n",
    "print()\n",
    "print(f'Device for model training/inference: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96ce8706-ff64-4576-87e3-5ec179646905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andreas/data/transformers/robert_frost.txt\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'data', 'transformers')\n",
    "textfile = os.path.join(data_dir, 'robert_frost.txt')\n",
    "print(textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9c74d44-3b04-4eb2-aba9-94ef4ccf7824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two roads diverged in a yellow wood,',\n",
       " 'And sorry I could not travel both',\n",
       " 'And be one traveler, long I stood',\n",
       " 'And looked down one as far as I could',\n",
       " 'To where it bent in the undergrowth;',\n",
       " 'Then took the other, as just as fair,',\n",
       " 'And having perhaps the better claim',\n",
       " 'Because it was grassy and wanted wear,',\n",
       " 'Though as for that the passing there',\n",
       " 'Had worn them really about the same,']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "lines = [line.rstrip() for line in open(textfile)]\n",
    "lines = [line for line in lines if len(line) > 0]\n",
    "display(lines[:10])\n",
    "\n",
    "# Text generation pipeline\n",
    "gen = pipeline(task='text-generation', device=device)\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52259fe6-f447-482c-ae7e-41cefe9aa95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "916d101b-60d9-4469-af89-e07197240b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, then I went to the '\n",
      "                    'point where my father and the driver were parked. At one '\n",
      "                    'point they were sitting in the rear of the car (a small '\n",
      "                    'car), and I got behind them and went for the'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f25f5a50-9b1f-49d4-9e9f-64c7acbcf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, only about 1.7 mi '\n",
      "                    'from the base of Mt'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, and in front of the '\n",
      "                    'building a large boulder crashed and'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, and as they '\n",
      "                    'approached it many children were playing on the'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0], num_return_sequences=3, max_length=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b394f4a-ebb0-459e-be82-2603813a4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, one on the top side, the other on\n",
      "the bottom, and each side was divided by a road.\n"
     ]
    }
   ],
   "source": [
    "# Let's try to write a multi-line poem\n",
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)\n",
    "\n",
    "out = gen(lines[0], max_length=30)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a042f1b6-3f11-403c-afb5-51665cb1e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural networks with attention have been used with great success in\n",
      "natural language procesing in humans, humans in cats, goats,\n",
      "chimpanzees, and humans in humans.  The results are now beginning to\n",
      "show that there is a direct correlation between attention networks in\n",
      "humans and cognitive performance in animals (Tau, 1994). In short, if\n",
      "there are different attention networks in humans and animals on\n",
      "different levels that influence human performance in terms of\n",
      "attention (or not), then it must be inferred from the fact that there\n",
      "are distinct cognitive function regions in humans, cats, humans, and\n",
      "animals that must co-occur across different social networks in a\n",
      "particular network environment.  These cognitive functions could\n",
      "account for the lack of direct association between attention and\n",
      "learning performance.\n",
      "\n",
      "The results from the neuroimaging study\n",
      "presented in Niebel and KÃ¼chen (2013) also show an indirect link\n",
      "between attention in humans and cognitive function.  These results\n",
      "indicate that attention was used in the brain of rats from one end of\n",
      "the brain to the other in connection with the visual system.  The rats\n",
      "were in a small group with a specific attention system and an\n",
      "attention deficit phenotype.  However, because of the non-specific\n",
      "nature of this group, the effect of these animals on cognitive\n",
      "functions on the animals was not observed.  This is consistent with\n",
      "behavioral effects of the attention problem treatment that result from\n",
      "misallocation of attention to two different areas of the brain.\n",
      "\n",
      "The\n",
      "brain regions responsible for the decision to focus on the visual\n",
      "system that are\n"
     ]
    }
   ],
   "source": [
    "# Better is text that is not poetry\n",
    "prompt = ('Neural networks with attention have been used with great success '\n",
    "          'in natural language procesing')\n",
    "\n",
    "out = gen(prompt, max_length=300)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
